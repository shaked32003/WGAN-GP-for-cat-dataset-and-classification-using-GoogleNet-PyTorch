{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba491590",
      "metadata": {
        "id": "ba491590"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import PIL\n",
        "import pdb\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms,datasets\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6d8b57",
      "metadata": {
        "id": "6d6d8b57"
      },
      "outputs": [],
      "source": [
        "def show(tensor, num=25,name=''):\n",
        "    data = tensor.detach().cpu()\n",
        "    gred = make_grid(data[:num],nrow=5).permute(1,2,0)\n",
        "    plt.imshow(gred)\n",
        "    plt.title(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17253e2f",
      "metadata": {
        "id": "17253e2f"
      },
      "outputs": [],
      "source": [
        "epochs = 130\n",
        "start_epoch = 0\n",
        "batch = 64\n",
        "gen_lr = 1e-4\n",
        "crit_lr = 0.00008\n",
        "z_dim = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "cur_step = 0\n",
        "crit_cycls = 5\n",
        "gan_losses =[]\n",
        "crit_losses = []\n",
        "show_step = 35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kl8ZIwdsItIi",
      "metadata": {
        "id": "Kl8ZIwdsItIi"
      },
      "outputs": [],
      "source": [
        "class Dog_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, paths, size=128):\n",
        "        self.sizes=[size, size]\n",
        "        items, labels=[],[]\n",
        "\n",
        "        for data in os.listdir(paths):\n",
        "            item = os.path.join(paths,data)\n",
        "            items.append(item)\n",
        "            labels.append(data)\n",
        "        self.items=items\n",
        "        self.labels=labels\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        data = PIL.Image.open(self.items[idx]).convert('RGB') \n",
        "        data = np.asarray(torchvision.transforms.Resize(self.sizes)(data)) \n",
        "        data = np.transpose(data, (2,0,1)).astype(np.float32, copy=False) \n",
        "        data = torch.from_numpy(data).div(255) \n",
        "        return data, self.labels[idx]\n",
        "\n",
        "\n",
        "paths = \"afhq/train/dog\"\n",
        "ds = Dog_Dataset(paths, size=512)\n",
        "dataloader = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "x,y= next(iter(dataloader))\n",
        "show(x)\n",
        "\n",
        "print('dataloader length: {}'.format(len(dataloader)))\n",
        "print('Dataset length: {}'.format(len(ds)))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30T1IO1_nMTq",
      "metadata": {
        "id": "30T1IO1_nMTq"
      },
      "outputs": [],
      "source": [
        "class Cat_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, paths, size=128):\n",
        "        self.sizes=[size, size]\n",
        "        items, labels=[],[]\n",
        "\n",
        "        for data in os.listdir(paths):\n",
        "            item = os.path.join(paths,data)\n",
        "            items.append(item)\n",
        "            labels.append(data)\n",
        "        self.items=items\n",
        "        self.labels=labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        data = PIL.Image.open(self.items[idx]).convert('RGB') \n",
        "        data = np.asarray(torchvision.transforms.Resize(self.sizes)(data)) \n",
        "        data = np.transpose(data, (2,0,1)).astype(np.float32, copy=False) \n",
        "        data = torch.from_numpy(data).div(255) \n",
        "        return data, self.labels[idx]\n",
        "\n",
        "\n",
        "paths = \"afhq/train/cat\"\n",
        "ds = Cat_Dataset(paths, size=512)\n",
        "dataloader = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "x,y= next(iter(dataloader))\n",
        "show(x)\n",
        "\n",
        "print('dataloader length: {}'.format(len(dataloader)))\n",
        "print('Dataset length: {}'.format(len(ds)))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IMXILHYLOIKo",
      "metadata": {
        "id": "IMXILHYLOIKo"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self, z_dim=64, d_dim=16):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim=z_dim\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, d_dim * 64, 4, 1, 0,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*64, d_dim*32, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*32),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*32, d_dim*16, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*16),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*16, d_dim*8, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*8),\n",
        "            nn.ReLU(True),            \n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*8, d_dim*4, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*4),\n",
        "            nn.ReLU(True),            \n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*4, d_dim*2, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim*2),\n",
        "            nn.ReLU(True),    \n",
        "\n",
        "            nn.ConvTranspose2d(d_dim*2, d_dim, 4, 2, 1,bias=False), \n",
        "            nn.BatchNorm2d(d_dim),\n",
        "            nn.ReLU(True),               \n",
        "\n",
        "            nn.ConvTranspose2d(d_dim, 3, 4, 2, 1,bias=False), \n",
        "            nn.Tanh() \n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)  \n",
        "        return self.gen(x)\n",
        "\n",
        "\n",
        "    def gen_noise(num, z_dim, device='cuda'):\n",
        "        return torch.randn(num, z_dim, device=device) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NgfmUhkRuC-_",
      "metadata": {
        "id": "NgfmUhkRuC-_"
      },
      "outputs": [],
      "source": [
        "class Critic(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_dim=16):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.crit = nn.Sequential(\n",
        "            nn.Conv2d(3, d_dim, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim, d_dim*2, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*2, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim*2, d_dim*4, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*4, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim*4, d_dim*8, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*8, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim*8, d_dim*16, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*16, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "              \n",
        "            nn.Conv2d(d_dim*16, d_dim*32, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*32, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim*32, d_dim*64, 4, 2, 1,bias=False), \n",
        "            nn.InstanceNorm2d(d_dim*64, affine=True), \n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(d_dim*64, 1, 4, 1, 0,bias=False), \n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        crit_pred = self.crit(image) \n",
        "        return crit_pred.view(len(crit_pred),-1)   \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9975f4af",
      "metadata": {
        "id": "9975f4af"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "\n",
        "    if isinstance(m,nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "665f5421",
      "metadata": {
        "id": "665f5421"
      },
      "outputs": [],
      "source": [
        "def get_gp(real , fake , crit, alpha, gamma=10):\n",
        "    mix_img = alpha*real + (1-alpha)*fake\n",
        "    mix_scores = critic(mix_img)\n",
        "    \n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs= mix_img,\n",
        "        outputs = mix_scores,\n",
        "        grad_outputs = torch.ones_like(mix_scores),\n",
        "        retain_graph = True,\n",
        "        create_graph= True)[0]\n",
        "    \n",
        "    gradient = gradient.view(len(gradient), -1)\n",
        "    gradient_norm = gradient.norm(2,dim=1)\n",
        "    gp = gamma*((gradient_norm-1)**2).mean()\n",
        "    \n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307b4b10",
      "metadata": {
        "id": "307b4b10"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(gan_path,critic_path):\n",
        "    state_gan = {'epoch':epoch,'model':gan,'optimizer':gan_opt}\n",
        "    state_critic = {'epoch':epoch,'model':critic,'optimizer':critic_opt}\n",
        "    torch.save(state_gan,gan_path)\n",
        "    torch.save(state_critic,critic_path)\n",
        "    \n",
        "def load_checkpoint(gan_path,critic_path):\n",
        "    state_gan = torch.load(gan_path)\n",
        "    state_critic = torch.load(critic_path)\n",
        "    \n",
        "    return state_gan,state_critic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821b73a5",
      "metadata": {
        "id": "821b73a5"
      },
      "outputs": [],
      "source": [
        "gan = Generator(z_dim).to(device)\n",
        "critic = Critic().to(device)\n",
        "gan =gan.to(device)\n",
        "critic =critic.to(device) \n",
        "\n",
        "#gan=gan.apply(init_weights)\n",
        "#critic=critic.apply(init_weights)\n",
        "\n",
        "\n",
        "gan_opt = torch.optim.Adam(gan.parameters(),lr= gen_lr, betas=(0.2,0.9))\n",
        "critic_opt = torch.optim.Adam(critic.parameters(),lr= crit_lr, betas=(0.5,0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f69d23",
      "metadata": {
        "id": "37f69d23"
      },
      "outputs": [],
      "source": [
        "for epoch in range(0,epochs):\n",
        "    for real , _ in tqdm(dataloader):\n",
        "        cur_bs = len(real)\n",
        "        real = real.to(device)\n",
        "        maen_critic_loss = 0\n",
        "        for _ in range(crit_cycls):\n",
        "            critic_opt.zero_grad()\n",
        "\n",
        "            noise = gen_noise(cur_bs,z_dim)\n",
        "            fake = gan(noise)\n",
        "            crit_fake_prad = critic(fake)\n",
        "            crit_real_prad = critic(real)\n",
        "\n",
        "            alpha = torch.rand((cur_bs,1,1,1),requires_grad = True).to(device)\n",
        "            gp = get_gp(real , fake.detach() , critic, alpha)\n",
        "            crit_loss = crit_fake_prad.mean() - crit_real_prad.mean() + gp\n",
        "\n",
        "            maen_critic_loss += crit_loss.item() / crit_cycls\n",
        "\n",
        "            crit_loss.backward(retain_graph=True)\n",
        "            critic_opt.step()\n",
        "\n",
        "        crit_losses.append(maen_critic_loss)    \n",
        "\n",
        "        gan_opt.zero_grad()\n",
        "        noise = gen_noise(cur_bs,z_dim)\n",
        "        fake = gan(noise)\n",
        "        crit_fake_prad = critic(fake)\n",
        "\n",
        "        gen_loss = - crit_fake_prad.mean()\n",
        "        gen_loss.backward(retain_graph=True)\n",
        "        gan_opt.step()\n",
        "\n",
        "        gan_losses.append(gen_loss.item())\n",
        "\n",
        "\n",
        "        if (cur_step % show_step == 0 and cur_step > 0):\n",
        "            show(fake, name='fake')\n",
        "            show(real, name='real')\n",
        "            print(\"epoch: {} , step: {} ,gen_loss: {}, crit_loss: {}\".format(epoch,cur_step,gen_loss,crit_loss))\n",
        "\n",
        "            plt.plot(\n",
        "              range(len(gan_losses)),\n",
        "              torch.Tensor(gan_losses),\n",
        "              label=\"Generator Loss\"\n",
        "            )\n",
        "\n",
        "            plt.plot(\n",
        "              range(len(gan_losses)),\n",
        "              torch.Tensor(crit_losses),\n",
        "              label=\"Critic Loss\"\n",
        "            )\n",
        "\n",
        "            plt.ylim(-150,150)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        cur_step+=1\n",
        "\n",
        "    print(\"Saving checkpoint: \", cur_step, epoch)\n",
        "    save_checkpoint(\"gen_cat \" + str(epoch),\"crit_cat \" + str(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_agdo6rY4Nyp",
      "metadata": {
        "id": "_agdo6rY4Nyp"
      },
      "outputs": [],
      "source": [
        "gan_dog_path,critic_dog_path = load_checkpoint(\"1gan_cat 78\",\"1crit_cat 78\")\n",
        "gan_dog = gan_dog_path['model']\n",
        "critic_dog = critic_dog_path['model']\n",
        "\n",
        "\n",
        "gan_cat_path,critic_cat_path = load_checkpoint(\"1gan_cat 78\",\"1crit_cat 78\")\n",
        "gan_cat = gan_cat_path['model']\n",
        "critic_cat = critic_cat_path['model']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MamtQ9p44K6V",
      "metadata": {
        "id": "MamtQ9p44K6V"
      },
      "outputs": [],
      "source": [
        "noise0 = gen_noise(batch, z_dim)\n",
        "fake_dog = gan_dog(noise0)\n",
        "show(fake_dog)\n",
        "plt.imshow(fake_dog[0].detach().cpu().permute(1,2,0).squeeze().clip(0,1))\n",
        "\n",
        "noise1 = gen_noise(batch, z_dim)\n",
        "fake_cat = gan_cat(noise1)\n",
        "show(fake_cat)\n",
        "plt.imshow(fake_cat[0].detach().cpu().permute(1,2,0).squeeze().clip(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XLWoz9cg5PmG",
      "metadata": {
        "id": "XLWoz9cg5PmG"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "os.mkdir(\"gan_img\")\n",
        "for _ in range(0,20):\n",
        "    if not os.path.exists(\"gan_img/1\"):\n",
        "        os.mkdir(\"gan_img/1\")\n",
        "    if not os.path.exists(\"gan_img/0\"):\n",
        "        os.mkdir(\"gan_img/0\")\n",
        "        \n",
        "    noise0 = gen_noise(batch, z_dim)\n",
        "    fake_dog = gan_dog(noise0)\n",
        "    \n",
        "    noise1 = gen_noise(batch, z_dim)\n",
        "    fake_cat = gan_cat(noise1)\n",
        "    \n",
        "    for idx in range(0,len(fake_cat)):\n",
        "        img = fake_dog[idx].detach().cpu().squeeze().clip(0,1)\n",
        "        save_image(img, os.path.join(\"gan_img/1\",\"dog \" + str(count) + \".jpg\"))\n",
        "\n",
        "        img = fake_cat[idx].detach().cpu().squeeze().clip(0,1)\n",
        "        save_image(img, os.path.join(\"gan_img/0\",\"cat \" + str(count) + \".jpg\"))\n",
        "        \n",
        "        count+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}